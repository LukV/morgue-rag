# Provider Configuration
# Choose embedding provider: "openai" or "huggingface" (default: huggingface)
EMBEDDING_PROVIDER=huggingface

# Choose LLM provider: "openai" or "ollama" (default: openai)
LLM_PROVIDER=ollama

# OpenAI API Configuration (only required if using OpenAI)
# OPENAI_API_KEY=your-api-key-here

# Ollama Configuration (for local LLMs)
OLLAMA_MODEL=deepseek-r1:latest
# OLLAMA_BASE_URL=http://localhost:11434

# Ollama timeout settings (important for macOS and large models)
OLLAMA_TIMEOUT=300.0  # 5 minutes timeout
OLLAMA_KEEP_ALIVE=5m  # Keep model loaded for 5 minutes

# Optional: Override default model settings
# OPENAI_MODEL=gpt-4
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# HuggingFace Embedding Models (free, no API key required)
# Popular options:
# - BAAI/bge-small-en-v1.5 (default, 33M params, good quality/speed balance)
# - BAAI/bge-base-en-v1.5 (110M params, better quality)
# - BAAI/bge-large-en-v1.5 (335M params, best quality)
# - sentence-transformers/all-MiniLM-L6-v2 (22M params, fast)
# - sentence-transformers/all-mpnet-base-v2 (110M params, high quality)
HUGGINGFACE_EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# Optional: RAG Configuration
# CHUNK_SIZE=512
# CHUNK_OVERLAP=50
# TOP_K=5

# Optional: Set temperature for deterministic output
# TEMPERATURE=0.0
# MAX_TOKENS=2000